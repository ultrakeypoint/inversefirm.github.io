"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[567],{5226:e=>{e.exports=JSON.parse('{"version":{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"tutorialSidebar":[{"type":"link","label":"Mango LLMBoost","href":"/","docId":"getting-started","unlisted":false},{"type":"link","label":"Tutorial","href":"/tutorial","docId":"tutorial","unlisted":false},{"type":"link","label":"Inference Server","href":"/inference-server","docId":"inference-server","unlisted":false},{"type":"category","label":"API Documentation","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"llmboost","href":"/api/llmboost","docId":"api/llmboost","unlisted":false}],"href":"/category/api-documentation"},{"type":"link","label":"Parallelism","href":"/parallelism","docId":"parallelism","unlisted":false}]},"docs":{"api/llmboost":{"id":"api/llmboost","title":"llmboost","description":"LLMBoost Objects","sidebar":"tutorialSidebar"},"getting-started":{"id":"getting-started","title":"Mango LLMBoost","description":"LLMBoost is a ready-to-deploy full stack AI inferencing server offering unprecedented performance and flexibility.","sidebar":"tutorialSidebar"},"inference-server":{"id":"inference-server","title":"Inference Server","description":"As well as the In-Process SDK, LLMBoost has an Inference Server option that can be started using the llmboost command line option.","sidebar":"tutorialSidebar"},"parallelism":{"id":"parallelism","title":"Parallelism","description":"LLMBoost supports multiple dimensions of parallelism, within a single node the two a user should consider are Tensor Parallelism(tp) and Data Parallelism(dp).","sidebar":"tutorialSidebar"},"tutorial":{"id":"tutorial","title":"Tutorial","description":"This tutorial demonstrates how to use the In-Process SDK of LLMBoost so that you can integrated it into your own application.","sidebar":"tutorialSidebar"}}}}')}}]);