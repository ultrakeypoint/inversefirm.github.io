"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[242],{3168:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>c,contentTitle:()=>i,default:()=>h,frontMatter:()=>r,metadata:()=>o,toc:()=>d});const o=JSON.parse('{"id":"inference-server","title":"Inference Server","description":"As well as the In-Process SDK, LLMBoost has an Inference Server option that can be started using the llmboost command line option.","source":"@site/docs/inference-server.md","sourceDirName":".","slug":"/inference-server","permalink":"/inference-server","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"sidebar_position":3},"sidebar":"tutorialSidebar","previous":{"title":"Tutorial","permalink":"/tutorial"},"next":{"title":"API Documentation","permalink":"/category/api-documentation"}}');var s=t(4848),l=t(8453);const r={sidebar_position:3},i="Inference Server",c={},d=[{value:"Deployment",id:"deployment",level:2},{value:"1. Single server (<code>llmboost serve</code>)",id:"1-single-server-llmboost-serve",level:3},{value:"2. Multi model deployment (<code>llmboost deploy</code>)",id:"2-multi-model-deployment-llmboost-deploy",level:3},{value:"Check deployment status",id:"check-deployment-status",level:4},{value:"Run Server-side Benchmark",id:"run-server-side-benchmark",level:4},{value:"Shutdown instance",id:"shutdown-instance",level:4},{value:"Interactive client",id:"interactive-client",level:2}];function a(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",p:"p",pre:"pre",...(0,l.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"inference-server",children:"Inference Server"})}),"\n",(0,s.jsxs)(n.p,{children:["As well as the In-Process SDK, LLMBoost has an Inference Server option that can be started using the ",(0,s.jsx)(n.code,{children:"llmboost"})," command line option."]}),"\n",(0,s.jsx)(n.h2,{id:"deployment",children:"Deployment"}),"\n",(0,s.jsx)(n.p,{children:"There are multiple deployment options:"}),"\n",(0,s.jsxs)(n.h3,{id:"1-single-server-llmboost-serve",children:["1. Single server (",(0,s.jsx)(n.code,{children:"llmboost serve"}),")"]}),"\n",(0,s.jsx)(n.p,{children:"This will run a single application server."}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"llmboost serve --model_path /models/models/Meta-Llama-3.1-8B-Instruct-FP8-KV --port 8011 --dp 8\n"})}),"\n",(0,s.jsxs)(n.h3,{id:"2-multi-model-deployment-llmboost-deploy",children:["2. Multi model deployment (",(0,s.jsx)(n.code,{children:"llmboost deploy"}),")"]}),"\n",(0,s.jsx)(n.p,{children:"LLMBoost supports the deployment of multiple models on a multi-GPU server. To use this feature, you'll need a configuration file that specifies the deployment details for each model. The configuration options are consistent with those used in LLMBoost benchmark runs. An example configuration file is shown below:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"common:\n  kv_cache_dtype: auto\n  host: 127.0.0.1\n\nmodels:\n  - model_name: Llama-3.2-1B-Instruct\n    model_path: /models/models/Meta-Llama-3.1-8B-Instruct-FP8-KV\n    port: 8011\n    tp: 1\n    dp: 2\n\n  - model_name: Llama-3.1-70B-Instruct\n    model_path: /models/models/Llama-3.1-70B-Instruct\n    port: 8012\n    tp: 2\n    dp: 2\n"})}),"\n",(0,s.jsx)(n.p,{children:"Finally, you can initiate the deployment by running :"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"llmboost deploy --config /workspace/examples/config/sample_config.yaml\n"})}),"\n",(0,s.jsx)(n.h4,{id:"check-deployment-status",children:"Check deployment status"}),"\n",(0,s.jsxs)(n.p,{children:["You can check the LLMBoost instances status by running ",(0,s.jsx)(n.code,{children:"llmboost status"}),", and will get similar output as below:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"+------+------------------------+---------+\n| Port |          Name          |  Status |\n+------+------------------------+---------+\n| 8011 | Llama-3.2-1B-Instruct  | running |\n| 8012 | Llama-3.1-70B-Instruct | running |\n+------+------------------------+---------+\n"})}),"\n",(0,s.jsx)(n.h4,{id:"run-server-side-benchmark",children:"Run Server-side Benchmark"}),"\n",(0,s.jsx)(n.p,{children:"After deploying the models, you can run a benchmark on each model by executing the following command:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"llmboost benchmark --port 8011 --num_prompts 100 --input_len 128 --output_len 128 --output_file /workspace/benchmarks/mi300/bench_result.csv \n"})}),"\n",(0,s.jsxs)(n.p,{children:["Explanation: Execute a benchmark on the server that is running on port ",(0,s.jsx)(n.code,{children:"8011"})," by sending ",(0,s.jsx)(n.code,{children:"100"})," prompts, each having an input and output length of ",(0,s.jsx)(n.code,{children:"128"})," tokens, and save the results in ",(0,s.jsx)(n.code,{children:"/workspace/benchmarks/mi300/bench_result.csv"}),"."]}),"\n",(0,s.jsx)(n.h4,{id:"shutdown-instance",children:"Shutdown instance"}),"\n",(0,s.jsxs)(n.p,{children:["You can run ",(0,s.jsx)(n.code,{children:"llmboost shutdown --port XXXX"})," to delete a specific instance. Or, you can use ",(0,s.jsx)(n.code,{children:"llmboost shutdown --all"})," to shutdown all instances in the current server."]}),"\n",(0,s.jsx)(n.h2,{id:"interactive-client",children:"Interactive client"}),"\n",(0,s.jsxs)(n.p,{children:["Once you have an LLMBoost instance up and running, you can use ",(0,s.jsx)(n.code,{children:"llmboost client"})," to connect to it."]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"llmboost client --port 8011\n"})})]})}function h(e={}){const{wrapper:n}={...(0,l.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(a,{...e})}):a(e)}},8453:(e,n,t)=>{t.d(n,{R:()=>r,x:()=>i});var o=t(6540);const s={},l=o.createContext(s);function r(e){const n=o.useContext(l);return o.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function i(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:r(e.components),o.createElement(l.Provider,{value:n},e.children)}}}]);